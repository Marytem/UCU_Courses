{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model & dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country      y  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset & clear redundant whitespaces\n",
    "cols = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation',\n",
    "          'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'y']\n",
    "\n",
    "adult_train = pd.read_csv('Census/adult.data', header = None)\n",
    "adult_test  = pd.read_csv('Census/adult.test', header = None)\n",
    "adult_train.columns = cols\n",
    "adult_test.columns = cols\n",
    "\n",
    "for col in adult_train.columns:\n",
    "    if col not in ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']:\n",
    "        adult_test[col] = adult_test[col].str.strip()\n",
    "        adult_train[col] = adult_train[col].str.strip()\n",
    "\n",
    "adult_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global most common substitution\n",
    "\n",
    "numeric_imputer = SimpleImputer(missing_values = 0, strategy = 'median')\n",
    "adult_test[['capital_loss', 'capital_gain']] = numeric_imputer.fit_transform(adult_test[['capital_loss', 'capital_gain']])\n",
    "adult_train[['capital_loss', 'capital_gain']] = numeric_imputer.fit_transform(adult_train[['capital_loss', 'capital_gain']])\n",
    "\n",
    "categoric_imputer = SimpleImputer(missing_values= '?',strategy='most_frequent')\n",
    "adult_train[['workclass', 'occupation', 'native_country']] = categoric_imputer.fit_transform(adult_train[['workclass', 'occupation', 'native_country']])\n",
    "adult_test[['workclass', 'occupation', 'native_country']] = categoric_imputer.fit_transform(adult_test[['workclass', 'occupation', 'native_country']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4.2 categorical to numerical\n",
    "cols_to_transform = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
    "test, train = pd.get_dummies(adult_test, columns=cols_to_transform), pd.get_dummies(adult_train, columns=cols_to_transform)\n",
    "\n",
    "# transform y\n",
    "train['y']= train.y.eq('>50K').mul(1)\n",
    "test['y']= test.y.eq('>50K.').mul(1)\n",
    "\n",
    "# add missing column to test dataset\n",
    "test['native_country_Holand-Netherlands'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7728263873959645, 0.7754437688102697, 0.7799837335414785)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.1\n",
    "compare_clf = LogisticRegression(C=10, solver='lbfgs', max_iter = 1000)\n",
    "\n",
    "x_train, y_train = train.loc[:, train.columns != 'y'], train['y']\n",
    "x_test, y_test = test.loc[:, test.columns != 'y'], test['y']\n",
    "\n",
    "compare_clf.fit(x_train, y_train)\n",
    "orig_predicted = compare_clf.predict(x_test)\n",
    "\n",
    "orig_train_score = compare_clf.score(x_train, y_train)\n",
    "orig_test_score = accuracy_score(y_test, orig_predicted)\n",
    "orig_cv_scores = cross_val_score(LogisticRegression(C=10, solver='lbfgs', max_iter = 1000), x_train.append(x_test, sort=False), y_train.append(y_test), scoring='accuracy', cv=20)\n",
    "orig_train_score, orig_test_score, orig_cv_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Misclassification noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1\n",
    "n = [0.01, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.766039</td>\n",
       "      <td>0.737784</td>\n",
       "      <td>0.680385</td>\n",
       "      <td>0.592457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775997</td>\n",
       "      <td>0.773355</td>\n",
       "      <td>0.765923</td>\n",
       "      <td>0.768687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.776198</td>\n",
       "      <td>0.754659</td>\n",
       "      <td>0.714754</td>\n",
       "      <td>0.650036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0.01      0.05      0.10      0.20\n",
       "0  0.766039  0.737784  0.680385  0.592457\n",
       "1  0.775997  0.773355  0.765923  0.768687\n",
       "2  0.776198  0.754659  0.714754  0.650036"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_col = train.y\n",
    "misclf_results = {} # dict of results: keys - n(percentage of noise), values - tuple of train,test,cv scores\n",
    "later_need_y = []\n",
    "\n",
    "for perc in n:\n",
    "#     invert y\n",
    "    update_col = orig_col.to_frame().replace({0: 1, 1: 0})\n",
    "#     insert 1-n % of NA in update column (so that 1-n% were not updated)\n",
    "    update_col.loc[update_col.sample(frac=1-perc).index, 'y'] = np.nan\n",
    "#     update n% of 'y' col in train\n",
    "    train.update(update_col)\n",
    "    \n",
    "    y_train = train.y\n",
    "    \n",
    "    if perc == 0.1: # save that y for 5th task\n",
    "        later_need_y = train.y\n",
    "    \n",
    "#     2.2\n",
    "    clf = LogisticRegression(C=10, solver='lbfgs', max_iter = 1000)\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    predicted = clf.predict(x_test)\n",
    "\n",
    "    train_score = clf.score(x_train, y_train)\n",
    "    test_score = accuracy_score(y_test, predicted)\n",
    "    cv_scores = cross_val_score(LogisticRegression(C=10, solver='lbfgs', max_iter = 1000), x_train.append(x_test, sort=False), y_train.append(y_test), scoring='accuracy', cv=20)\n",
    "    \n",
    "    misclf_results[perc] = (train_score, test_score, cv_scores.mean())\n",
    "    \n",
    "train['y'] = orig_col\n",
    "\n",
    "pd.DataFrame(data=misclf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01, 0.05]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.3 show safe percentage of noise in the target col using cv_score\n",
    "safe_fracts = []\n",
    "for perc in n:\n",
    "    if orig_cv_scores.mean() - misclf_results[perc][1] <= 0.01:\n",
    "        safe_fracts.append(perc)\n",
    "safe_fracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.766039</td>\n",
       "      <td>0.737784</td>\n",
       "      <td>0.680385</td>\n",
       "      <td>0.592457</td>\n",
       "      <td>0.772826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775997</td>\n",
       "      <td>0.773355</td>\n",
       "      <td>0.765923</td>\n",
       "      <td>0.768687</td>\n",
       "      <td>0.775444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.776198</td>\n",
       "      <td>0.754659</td>\n",
       "      <td>0.714754</td>\n",
       "      <td>0.650036</td>\n",
       "      <td>0.779984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0.01      0.05       0.1       0.2  original\n",
       "0  0.766039  0.737784  0.680385  0.592457  0.772826\n",
       "1  0.775997  0.773355  0.765923  0.768687  0.775444\n",
       "2  0.776198  0.754659  0.714754  0.650036  0.779984"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclf_comp_table = pd.DataFrame(data=misclf_results)\n",
    "misclf_comp_table['original'] = np.array([orig_train_score, orig_test_score, orig_cv_scores.mean()])\n",
    "misclf_comp_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Attribute noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.805442</td>\n",
       "      <td>0.806578</td>\n",
       "      <td>0.771045</td>\n",
       "      <td>0.771506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.805847</td>\n",
       "      <td>0.809533</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.775935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.778142</td>\n",
       "      <td>0.781500</td>\n",
       "      <td>0.781337</td>\n",
       "      <td>0.780907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0.01      0.05      0.10      0.20\n",
       "0  0.805442  0.806578  0.771045  0.771506\n",
       "1  0.805847  0.809533  0.776119  0.775935\n",
       "2  0.778142  0.781500  0.781337  0.780907"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_age = adult_train['age']\n",
    "orig_edu_num = adult_train['education_num']\n",
    "orig_race = adult_train['race']\n",
    "\n",
    "from copy import deepcopy\n",
    "orig_train = deepcopy(adult_train)\n",
    "orig_test = deepcopy(adult_test)\n",
    "train, test = deepcopy(adult_train), deepcopy(adult_test)\n",
    "\n",
    "attr_results = {} # dict of results: keys - n(percentage of noise), values - tuple of train,test,cv scores\n",
    "\n",
    "for perc in n:\n",
    "    \n",
    "#     3.1 Randomly negate n% of the values of the age attribute\n",
    "    update_col = - train.age.to_frame()\n",
    "    update_col.loc[update_col.sample(frac=1-perc).index, 'age'] = np.nan\n",
    "    train.update(update_col)\n",
    "    \n",
    "#     3.2 Randomly replace n% of the values of education_num attribute with random large numbers in range [20,100]\n",
    "    update_col = pd.DataFrame(np.random.randint(20,100,size=(train['education_num'].shape[0], 1)))\n",
    "    update_col.loc[update_col.sample(frac=1-perc).index, 'education_num'] = np.nan\n",
    "    train.update(update_col)\n",
    "    \n",
    "#     3.3 Randomly replace n% of the values of this attribue with any other random race from the set of existing races\n",
    "    train.loc[train.sample(frac=perc).index, 'race'] = pd.DataFrame(np.random.choice(adult_train['race'].unique(), size=(train['education_num'].size)))\n",
    "    \n",
    "#     3.4 \n",
    "    test, train = pd.get_dummies(test, columns=cols_to_transform), pd.get_dummies(train, columns=cols_to_transform)\n",
    "    train['y']= train.y.eq('>50K').mul(1)\n",
    "    test['y']= test.y.eq('>50K.').mul(1)\n",
    "\n",
    "    clf = LogisticRegression(C=10, solver='lbfgs', max_iter = 1000)\n",
    "    x_train, y_train = train.loc[:, train.columns != 'y'], train['y']\n",
    "    \n",
    "    clf.fit(x_train, y_train)\n",
    "    predicted = clf.predict(x_test)\n",
    "\n",
    "    train_score = clf.score(x_train, y_train)\n",
    "    test_score = accuracy_score(y_test, predicted)\n",
    "    cv_scores = cross_val_score(LogisticRegression(C=10, solver='lbfgs', max_iter = 1000), x_train.append(x_test, sort=False), y_train.append(y_test), scoring='accuracy', cv=20)\n",
    "    \n",
    "    attr_results[perc] = (train_score, test_score, cv_scores.mean())\n",
    "    \n",
    "    train = orig_train\n",
    "    test = orig_test\n",
    "\n",
    "pd.DataFrame(data=attr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.032616</td>\n",
       "      <td>-0.033752</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.001321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.030404</td>\n",
       "      <td>-0.034089</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>-0.000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001841</td>\n",
       "      <td>-0.001516</td>\n",
       "      <td>-0.001353</td>\n",
       "      <td>-0.000923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0.01      0.05      0.10      0.20\n",
       "0 -0.032616 -0.033752  0.001781  0.001321\n",
       "1 -0.030404 -0.034089 -0.000676 -0.000491\n",
       "2  0.001841 -0.001516 -0.001353 -0.000923"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.5\n",
    "differences = {} # keys - percentage(n), values accuracy differences with original on train, test and cv\n",
    "for perc in n:\n",
    "    train_diff = orig_train_score - attr_results[perc][0]\n",
    "    test_diff = orig_test_score - attr_results[perc][1]\n",
    "    cv_diff = orig_cv_scores.mean() - attr_results[perc][2]\n",
    "    differences[perc] = (train_diff, test_diff, cv_diff)\n",
    "pd.DataFrame(data=differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see sometimes the model performs even better with noise in data. That can be because the corrupted columns have no influence on 'y', or because the data could be already with noise, or by some different reason attribute noise got model to train better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Impact comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.766039</td>\n",
       "      <td>0.737784</td>\n",
       "      <td>0.680385</td>\n",
       "      <td>0.592457</td>\n",
       "      <td>0.772826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775997</td>\n",
       "      <td>0.773355</td>\n",
       "      <td>0.765923</td>\n",
       "      <td>0.768687</td>\n",
       "      <td>0.775444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.776198</td>\n",
       "      <td>0.754659</td>\n",
       "      <td>0.714754</td>\n",
       "      <td>0.650036</td>\n",
       "      <td>0.779984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0.01      0.05       0.1       0.2  original\n",
       "0  0.766039  0.737784  0.680385  0.592457  0.772826\n",
       "1  0.775997  0.773355  0.765923  0.768687  0.775444\n",
       "2  0.776198  0.754659  0.714754  0.650036  0.779984"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1. Build a table to compare accuracy of the model on the original dataset with models based on datasets\n",
    "# with different types and levels of noise introduced.\n",
    "misclf_comp_table = pd.DataFrame(data=misclf_results)\n",
    "misclf_comp_table['original'] = np.array([orig_train_score, orig_test_score, orig_cv_scores.mean()])\n",
    "misclf_comp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.805442</td>\n",
       "      <td>0.806578</td>\n",
       "      <td>0.771045</td>\n",
       "      <td>0.771506</td>\n",
       "      <td>0.772826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.805847</td>\n",
       "      <td>0.809533</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.775935</td>\n",
       "      <td>0.775444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.778142</td>\n",
       "      <td>0.781500</td>\n",
       "      <td>0.781337</td>\n",
       "      <td>0.780907</td>\n",
       "      <td>0.779984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0.01      0.05       0.1       0.2  original\n",
       "0  0.805442  0.806578  0.771045  0.771506  0.772826\n",
       "1  0.805847  0.809533  0.776119  0.775935  0.775444\n",
       "2  0.778142  0.781500  0.781337  0.780907  0.779984"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_comp_table = pd.DataFrame(data=attr_results)\n",
    "attr_comp_table['original'] = np.array([orig_train_score, orig_test_score, orig_cv_scores.mean()])\n",
    "attr_comp_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2. \n",
    "\n",
    "Class noise influences more, because if we have a mistake in a target - the whole row is a mistake, but if we have just an attribute mistake - the model can still use other info in a row with that mistake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3\n",
    "\n",
    "Depends on the data - we should analyse it and then decide which noise is worse.\n",
    "Usually misclassification noise seems to be more of a problem, because it influences target variable, which is usually most valuable in a dataset.\n",
    "\n",
    "But it also could be that we have very valuable attributes corrupted in data and they have big negative impact on our model, so we should address this noise first in that case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Misclassification noise elimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1\n",
    "test, train = pd.get_dummies(adult_test, columns=cols_to_transform), pd.get_dummies(adult_train, columns=cols_to_transform)\n",
    "train.y = later_need_y\n",
    "test['y']= test.y.eq('>50K.').mul(1)\n",
    "test['native_country_Holand-Netherlands'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2\n",
    "# split dataset to Ð“=5 datasets\n",
    "part_size = int(len(train)*0.2)\n",
    "parts = [train[:part_size], train[part_size : 2*part_size], train[2*part_size : 3*part_size], train[3*part_size : 4*part_size], train[4*part_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [array([0., 0., 1., ..., 1., 0., 1.]),\n",
       "  array([1., 1., 0., ..., 1., 1., 1.]),\n",
       "  array([1., 1., 0., ..., 0., 1., 0.]),\n",
       "  array([0., 1., 1., ..., 0., 1., 0.]),\n",
       "  array([0., 1., 0., ..., 1., 1., 0.])],\n",
       " 1: [array([1., 1., 0., ..., 0., 0., 0.]),\n",
       "  array([0., 1., 0., ..., 0., 1., 1.]),\n",
       "  array([1., 0., 1., ..., 1., 0., 0.]),\n",
       "  array([1., 1., 1., ..., 0., 1., 0.]),\n",
       "  array([0., 0., 0., ..., 0., 0., 0.])],\n",
       " 2: [array([0., 1., 1., ..., 0., 1., 0.]),\n",
       "  array([0., 1., 1., ..., 1., 0., 1.]),\n",
       "  array([0., 1., 0., ..., 0., 0., 1.]),\n",
       "  array([1., 0., 0., ..., 0., 0., 0.]),\n",
       "  array([1., 0., 1., ..., 0., 0., 0.])],\n",
       " 3: [array([0., 1., 1., ..., 0., 0., 0.]),\n",
       "  array([1., 0., 0., ..., 1., 1., 1.]),\n",
       "  array([0., 0., 0., ..., 1., 1., 0.]),\n",
       "  array([1., 0., 0., ..., 1., 0., 0.]),\n",
       "  array([1., 1., 0., ..., 1., 0., 1.])],\n",
       " 4: [array([0., 0., 1., ..., 1., 1., 1.]),\n",
       "  array([1., 0., 1., ..., 0., 1., 1.]),\n",
       "  array([1., 1., 0., ..., 1., 0., 0.]),\n",
       "  array([0., 0., 0., ..., 1., 0., 1.]),\n",
       "  array([1., 0., 1., ..., 0., 0., 0.])]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#key - index of parts of data in parts[], value - list where first item is real y, and the rest - predictions\n",
    "predicts = {} \n",
    "\n",
    "for part_num in range(len(parts)):\n",
    "    predicts[part_num] = [ np.array(parts[part_num]['y'].tolist()) ]\n",
    "    \n",
    "for part_num in range(len(parts)):\n",
    "    x_part, y_part = parts[part_num].loc[:, parts[part_num].columns != 'y'], parts[part_num]['y']\n",
    "    tree = DecisionTreeClassifier().fit(x_part, y_part)\n",
    "    for pred_part_num in range(len(parts)):\n",
    "        if pred_part_num != part_num:\n",
    "            predicts[pred_part_num].append(tree.predict(parts[pred_part_num].loc[:, parts[pred_part_num].columns != 'y']))\n",
    "    \n",
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32561"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of votes, where vote is a label which majority of classifiers predicted\n",
    "# if classifiers 'voted' 2:2 we also count a 'vote' of a real 'y'\n",
    "voting = []\n",
    "for npart in range(len(parts)):\n",
    "    for nrow in range(parts[npart].shape[0]):\n",
    "#         having sum>=3  means we have 3+(majority) predictions of 1 so we append 1 to votes, <3 - otherwise\n",
    "#         we treat real 'y' as another prediction as without it we would have a possibility of even number of votes\n",
    "        voting.append( int(np.sum(np.array(predicts[npart])[:,nrow]) >= 3) )\n",
    "len(voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6574122416387703, 0.7686874270622198, 0.6970851265459903)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since we have binary classification case, we can use votes list as the column iself\n",
    "# (it is the same as updating a column where misclassification occured)\n",
    "train.y = pd.Series(voting)\n",
    "\n",
    "compare_clf = LogisticRegression(C=10, solver='lbfgs', max_iter = 1000)\n",
    "\n",
    "x_train, y_train = train.loc[:, train.columns != 'y'], train['y']\n",
    "x_test, y_test = test.loc[:, test.columns != 'y'], test['y']\n",
    "\n",
    "compare_clf.fit(x_train, y_train)\n",
    "CVCF_predicted = compare_clf.predict(x_test)\n",
    "\n",
    "CVCF_train_score = compare_clf.score(x_train, y_train)\n",
    "CVCF_test_score = accuracy_score(y_test, CVCF_predicted)\n",
    "CVCF_cv_scores = cross_val_score(LogisticRegression(C=10, solver='lbfgs', max_iter = 1000), x_train.append(x_test, sort=False), y_train.append(y_test), scoring='accuracy', cv=20)\n",
    "CVCF_train_score, CVCF_test_score, CVCF_cv_scores.mean()\n",
    "\n",
    "CVCF_results = {}\n",
    "CVCF_results['CVCF_DesTrees'] = (CVCF_train_score, CVCF_test_score, CVCF_cv_scores.mean())\n",
    "CVCF_results['CVCF_DesTrees']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failure(\n",
    "The accuracy is way worse than original, because untuned DecisionTreeClassifier() gives around 52% of accuracy. Now, we __try__ the same with __supposedly tuned__ xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renewing data\n",
    "test, train = pd.get_dummies(adult_test, columns=cols_to_transform), pd.get_dummies(adult_train, columns=cols_to_transform)\n",
    "train.y = later_need_y\n",
    "test['y']= test.y.eq('>50K.').mul(1)\n",
    "test['native_country_Holand-Netherlands'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [array([0., 0., 1., ..., 1., 0., 1.]),\n",
       "  array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  array([0., 1., 0., ..., 0., 0., 0.]),\n",
       "  array([0., 1., 0., ..., 0., 0., 0.]),\n",
       "  array([0., 1., 0., ..., 0., 0., 0.])],\n",
       " 1: [array([1., 1., 0., ..., 0., 0., 0.]),\n",
       "  array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  array([0., 0., 1., ..., 0., 0., 0.]),\n",
       "  array([1., 0., 1., ..., 0., 0., 0.]),\n",
       "  array([0., 1., 0., ..., 0., 0., 0.])],\n",
       " 2: [array([0., 1., 1., ..., 0., 1., 0.]),\n",
       "  array([0., 0., 1., ..., 0., 0., 0.]),\n",
       "  array([0., 0., 0., ..., 0., 0., 1.]),\n",
       "  array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  array([0., 0., 1., ..., 0., 0., 0.])],\n",
       " 3: [array([0., 1., 1., ..., 0., 0., 0.]),\n",
       "  array([1., 0., 0., ..., 0., 0., 0.]),\n",
       "  array([0., 0., 0., ..., 0., 0., 0.]),\n",
       "  array([0., 0., 0., ..., 0., 0., 1.]),\n",
       "  array([0., 0., 0., ..., 0., 0., 0.])],\n",
       " 4: [array([0., 0., 1., ..., 1., 1., 1.]),\n",
       "  array([0., 0., 1., ..., 0., 0., 1.]),\n",
       "  array([0., 0., 0., ..., 0., 0., 1.]),\n",
       "  array([0., 0., 0., ..., 0., 0., 1.]),\n",
       "  array([0., 0., 0., ..., 0., 0., 1.])]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "predicts = {} #key - index of parts of data in parts[], value - list\n",
    "\n",
    "for part_num in range(len(parts)):\n",
    "    predicts[part_num] = [ np.array(parts[part_num]['y'].tolist()) ]\n",
    "    \n",
    "for part_num in range(len(parts)):\n",
    "    x_part, y_part = parts[part_num].loc[:, parts[part_num].columns != 'y'], parts[part_num]['y']\n",
    "    tree = XGBClassifier(max_depth=6, learning_rate=0.03, n_estimators=100, n_jobs=8, gamma=0.01, min_child_weight=5, max_delta_step=4, subsample=0.3, colsample_bytree=0.7, reg_lambda=2, scale_pos_weight=1, base_score=0.5, random_state=0).fit(x_part, y_part)\n",
    "    for pred_part_num in range(len(parts)):\n",
    "        if pred_part_num != part_num:\n",
    "            predicts[pred_part_num].append(tree.predict(parts[pred_part_num].loc[:, parts[pred_part_num].columns != 'y']))\n",
    "    \n",
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32561"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting = []\n",
    "for npart in range(len(parts)):\n",
    "    for nrow in range(parts[npart].shape[0]):\n",
    "        voting.append( int(np.sum(np.array(predicts[npart])[:,nrow]) >= 3) )\n",
    "len(voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8760787445103038, 0.8009336035870033, 0.8186778477204155)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.y = pd.Series(voting)\n",
    "\n",
    "compare_clf = LogisticRegression(C=10, solver='lbfgs', max_iter = 1000)\n",
    "\n",
    "x_train, y_train = train.loc[:, train.columns != 'y'], train['y']\n",
    "x_test, y_test = test.loc[:, test.columns != 'y'], test['y']\n",
    "\n",
    "compare_clf.fit(x_train, y_train)\n",
    "CVCF_predicted = compare_clf.predict(x_test)\n",
    "\n",
    "CVCF_train_score = compare_clf.score(x_train, y_train)\n",
    "CVCF_test_score = accuracy_score(y_test, CVCF_predicted)\n",
    "CVCF_cv_scores = cross_val_score(LogisticRegression(C=10, solver='lbfgs', max_iter = 1000), x_train.append(x_test, sort=False), y_train.append(y_test), scoring='accuracy', cv=20)\n",
    "\n",
    "CVCF_results['CVCF_xgb'] = (CVCF_train_score, CVCF_test_score, CVCF_cv_scores.mean())\n",
    "CVCF_results['CVCF_xgb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yay! Success)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3\n",
    "What percent of mislabled records you fixed using this method? Is it possible to do better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34955928871963393"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_cols = later_need_y.add(pd.Series(voting)).to_frame()\n",
    "sum_cols[sum_cols[0] == 1].shape[0]/train.shape[0] # fraction of updated labes using CVCF with xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first case, when we used decision trees we actually started mislabling data even more because of the bad classification accuracy of our decisiontree model - ~52%. This led to decrease of final regression accuracy on that data.\n",
    "\n",
    "Then we used tuned xgboost classifier with better accuracy and we got significant improvement in final regression accuracy on our data. CVCF on xgboost base updated 35.44% of noise data which is even more than we initially imputed in our data (10%). That is why we have better accuracy than on initial train dataset. If we go further with tuning we can do even better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVCF_DesTrees</th>\n",
       "      <th>CVCF_xgb</th>\n",
       "      <th>10%noise</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.657412</td>\n",
       "      <td>0.876079</td>\n",
       "      <td>0.680385</td>\n",
       "      <td>0.772826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.768687</td>\n",
       "      <td>0.800934</td>\n",
       "      <td>0.765923</td>\n",
       "      <td>0.775444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.697085</td>\n",
       "      <td>0.818678</td>\n",
       "      <td>0.714754</td>\n",
       "      <td>0.779984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CVCF_DesTrees  CVCF_xgb  10%noise  original\n",
       "0       0.657412  0.876079  0.680385  0.772826\n",
       "1       0.768687  0.800934  0.765923  0.775444\n",
       "2       0.697085  0.818678  0.714754  0.779984"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.4\n",
    "CVCF_comp_table = pd.DataFrame(data=CVCF_results)\n",
    "CVCF_comp_table['10%noise'] = np.array(misclf_results[0.1])\n",
    "CVCF_comp_table['original'] = np.array([orig_train_score, orig_test_score, orig_cv_scores.mean()])\n",
    "\n",
    "CVCF_comp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
